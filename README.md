# Асинхронный парсер PEP
## Описание проекта
Проект представляет собой асинхронный парсер для документов PEP (Python Enhancement Proposals) на базе фреймворка Scrapy. Парсер собирает информацию о всех опубликованных PEP и анализирует их статус. Собранные данные сохраняются в формате .csv в директорию results/.

## Основные функции:

**Парсинг списка PEP:**
    -Парсер находит ссылки на все опубликованные PEP на официальном сайте Python.
**Сбор детальной информации:**
    Переходит на страницы каждого PEP и собирает следующие данные:
    - **Номер PEP**
    - **Название PEP**
    - **Статус PEP**
**Обработка и анализ данных:**
    -Подсчитывается количество PEP в каждом статусе.
    -Определяется общее количество PEP.
**Сохранение данных:**
    -Все собранные данные сохраняются в `.csv` файлы в директорию `results/`.
## Используемые технологии

**Python 3.x** - язык программирования.
**Scrapy** - фреймворк для парсинга и сбора данных.
**CSV** - формат для хранения и обработки данных.

## Инструкция по установке и запуску

Склонировать репозиторий:
**git clone https://github.com/lokotkovnv/scrapy_parser_pep** 
Создать и активировать виртуальное окружение:
**python -m venv venv**
**source venv\Scripts\activate**
Установка зависимостей:
**pip install -r requirements.txt**
Запуск парсера:
Для запуска парсера в корневой директории проекта выполните команду:
**scrapy crawl pep**

## Примеры работы
После запуска парсера в директории results/ будут созданы .csv файлы с результатами. Например:

results/status_summary_2024-06-23_18-45-00.csv
Файл будет содержать данные в следующем формате:

Статус	Количество
Active	20
Final	30
Deferred	5
Rejected	10
Total	65


### Автор
### Локотков Никита (https://github.com/lokotkovnv)
